{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgNjd9RfVcQc",
        "outputId": "7588bada-37cd-4667-f209-25fe35915ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4Fm7AAQXVyy",
        "outputId": "37d25933-ba88-4a00-9809-be05a412d55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I love learning Natural Language Processing! Don't you? ðŸ˜Š #NLP\""
      ],
      "metadata": {
        "id": "QYuREeB1XX5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "\n",
        "wt = WhitespaceTokenizer()\n",
        "print(wt.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRUfdpotXbeG",
        "outputId": "499c8c63-6e93-4759-80ef-4b829d7c2308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'love', 'learning', 'Natural', 'Language', 'Processing!', \"Don't\", 'you?', 'ðŸ˜Š', '#NLP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "\n",
        "print(wordpunct_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKPDWxHWXdWf",
        "outputId": "c00be785-ed39-4d51-a45c-4494f11fb8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'love', 'learning', 'Natural', 'Language', 'Processing', '!', 'Don', \"'\", 't', 'you', '?', 'ðŸ˜Š', '#', 'NLP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "tbt = TreebankWordTokenizer()\n",
        "print(tbt.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3lQc2ieXgbn",
        "outputId": "8d664c66-9ad7-40ab-b9df-8a725ee3c892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'love', 'learning', 'Natural', 'Language', 'Processing', '!', 'Do', \"n't\", 'you', '?', 'ðŸ˜Š', '#', 'NLP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "tt = TweetTokenizer()\n",
        "print(tt.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV5GJpd3XnCz",
        "outputId": "7fc636ce-9d1b-43b5-f5e3-fe123c756bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'love', 'learning', 'Natural', 'Language', 'Processing', '!', \"Don't\", 'you', '?', 'ðŸ˜Š', '#NLP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import MWETokenizer\n",
        "\n",
        "mwe = MWETokenizer([('Natural', 'Language', 'Processing!')], separator='_')\n",
        "print(mwe.tokenize(text.split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcPMjwPtXpI4",
        "outputId": "cdd44b0d-fad8-4abc-c5d8-008461bd59f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'love', 'learning', 'Natural_Language_Processing!', \"Don't\", 'you?', 'ðŸ˜Š', '#NLP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "words = [\"playing\", \"plays\", \"played\", \"studies\"]\n",
        "\n",
        "for word in words:\n",
        "    print(word, \"â†’\", ps.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZYCqK4TXrc-",
        "outputId": "fa71e460-34f4-4fd8-8cf8-4d780c636aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "playing â†’ play\n",
            "plays â†’ play\n",
            "played â†’ play\n",
            "studies â†’ studi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "ss = SnowballStemmer(\"english\")\n",
        "\n",
        "for word in words:\n",
        "    print(word, \"â†’\", ss.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVHVn-w0XuiG",
        "outputId": "8906960d-5840-4e73-b6f4-7b12b0095672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "playing â†’ play\n",
            "plays â†’ play\n",
            "played â†’ play\n",
            "studies â†’ studi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(\"running â†’\", lemmatizer.lemmatize(\"running\", pos=wordnet.VERB))\n",
        "print(\"better  â†’\", lemmatizer.lemmatize(\"better\", pos=wordnet.ADJ))\n",
        "print(\"cars    â†’\", lemmatizer.lemmatize(\"cars\", pos=wordnet.NOUN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMsqQH9cXzw5",
        "outputId": "b8d6a995-38c0-4b59-a4bb-1dd9f67b1500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running â†’ run\n",
            "better  â†’ good\n",
            "cars    â†’ car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def get_pos(word):\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    return {\n",
        "        'J': wordnet.ADJ,\n",
        "        'V': wordnet.VERB,\n",
        "        'N': wordnet.NOUN,\n",
        "        'R': wordnet.ADV\n",
        "    }.get(tag, wordnet.NOUN)\n",
        "\n",
        "for word in [\"teeth\", \"better\", \"cars\"]:\n",
        "    print(word, \"â†’\", lemmatizer.lemmatize(word, get_pos(word)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrCnAV3TkXXm",
        "outputId": "bc8dd4ac-bcf7-4b04-ac59-5032f8ee023c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teeth â†’ teeth\n",
            "better â†’ well\n",
            "cars â†’ car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatizing Technique\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag\n",
        "\n",
        "# REQUIRED for newer NLTK versions\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatization_words = [\"swimming\", \"better\", \"cars\", \"studies\"]\n",
        "\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "print(\"\\nLemmatization:\")\n",
        "for word, tag in pos_tag(lemmatization_words):\n",
        "    print(word, \"â†’\", lemmatizer.lemmatize(word, pos=get_wordnet_pos(tag)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDaWJ1MHlKCh",
        "outputId": "e869dbaa-d1bf-4e48-c682-2cdf6312ff51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lemmatization:\n",
            "swimming â†’ swim\n",
            "better â†’ good\n",
            "cars â†’ car\n",
            "studies â†’ study\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    }
  ]
}